{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e09001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtsam\n",
    "from gtsam import Point2, Pose2, symbol\n",
    "import numpy as np\n",
    "import math\n",
    "import time \n",
    "import plotly.express as px\n",
    "\n",
    "from gtsam.utils import plot # Needs matplotlib\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng()\n",
    "\n",
    "NM = gtsam.noiseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1371f955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 4090 odometry entries.\n"
     ]
    }
   ],
   "source": [
    "odometry_data = {}\n",
    "data_file_dr = gtsam.findExampleDataFile(\"Plaza2_DR.txt\")\n",
    "odo_times_list = []\n",
    "for row in np.loadtxt(data_file_dr):\n",
    "    t, distance_traveled, delta_heading = row\n",
    "    odometry_data[t] = Pose2(distance_traveled, 0, delta_heading)\n",
    "    odo_times_list.append(t)\n",
    "\n",
    "odo_times_list.sort() # Ensure times are sorted\n",
    "M = len(odometry_data)\n",
    "print(f\"Read {M} odometry entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51316a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1816 range triples for 4 unique landmarks.\n"
     ]
    }
   ],
   "source": [
    "triples = []\n",
    "landmark_ids = set()\n",
    "data_file_td = gtsam.findExampleDataFile(\"Plaza2_TD.txt\")\n",
    "for row in np.loadtxt(data_file_td):\n",
    "    t, sender, receiver, _range = row\n",
    "    landmark_id = int(receiver)\n",
    "    triples.append((t, landmark_id, _range))\n",
    "    landmark_ids.add(landmark_id)\n",
    "\n",
    "K = len(triples)\n",
    "sorted_landmark_ids = sorted(list(landmark_ids))\n",
    "print(f\"Read {K} range triples for {len(landmark_ids)} unique landmarks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fb0ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmaR = 50        # range standard deviation (matches MATLAB)\n",
    "sigmaInitialLandmark = 1.0 # Stddev for random landmark init (matches MATLAB)\n",
    "robust = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee67ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Noise parameters (mirrors MATLAB script)\n",
    "priorSigmas = gtsam.Point3(1, 1, math.pi)  # Prior on Pose 0\n",
    "pointPriorSigmas = gtsam.Point2(1, 1) # Loose prior on landmarks\n",
    "odoSigmas = gtsam.Point3(0.05, 0.01, 0.2) # Odometry noise\n",
    "\n",
    "priorNoise = NM.Diagonal.Sigmas(priorSigmas) # prior on pose 0\n",
    "pointPriorNoise = NM.Diagonal.Sigmas(pointPriorSigmas) # loose LM prior\n",
    "odoNoise = NM.Diagonal.Sigmas(odoSigmas)     # odometry\n",
    "\n",
    "# Range noise\n",
    "gaussian = NM.Isotropic.Sigma(1, sigmaR)     # non-robust\n",
    "base = NM.mEstimator.Tukey(15) # Tukey M-estimator like MATLAB\n",
    "tukey = NM.Robust.Create(base, gaussian)  # robust\n",
    "rangeNoise = tukey if robust else gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f71804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Landmarks...\n",
      "Initialized 4 landmarks.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Factor Graph and Initial Values\n",
    "graph = gtsam.NonlinearFactorGraph()\n",
    "initial = gtsam.Values()\n",
    "\n",
    "# Add prior on first pose\n",
    "# Estimate pose0 from the first odometry time's neighborhood or use a fixed reasonable guess.\n",
    "# Using the same value as the iSAM example for consistency.\n",
    "pose0 = Pose2(-34.2086489999201, 45.3007639991120, math.pi - 2.021089)\n",
    "graph.add(gtsam.PriorFactorPose2(0, pose0, priorNoise))\n",
    "initial.insert(0, pose0)\n",
    "\n",
    "# Initialize Landmarks (similar to MATLAB approach)\n",
    "print(\"Initializing Landmarks...\")\n",
    "for j in sorted_landmark_ids:\n",
    "    landmark_key = symbol('L', j)\n",
    "    # Initialize randomly around origin (adjust scale if needed)\n",
    "    initial_point = Point2(sigmaInitialLandmark * rng.normal(), sigmaInitialLandmark * rng.normal())\n",
    "    initial.insert(landmark_key, initial_point)\n",
    "    # Optional: Add a loose prior to help localization if landmarks are poorly constrained\n",
    "    # graph.add(gtsam.PriorFactorPoint2(landmark_key, Point2(0,0), pointPriorNoise))\n",
    "print(f\"Initialized {len(sorted_landmark_ids)} landmarks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d87b68b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Pose Chain and Odometry Factors...\n",
      "Added 4090 odometry factors and initial pose estimates.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding Pose Chain and Odometry Factors...\")\n",
    "lastPose = pose0\n",
    "pose_times = [odo_times_list[0]] # Approximate time for pose 0\n",
    "# Loop over odometry measurements\n",
    "for i, t in enumerate(odo_times_list, 1):\n",
    "    # get odometry measurement for this time step\n",
    "    odometry = odometry_data[t]\n",
    "\n",
    "    # add odometry factor\n",
    "    graph.add(gtsam.BetweenFactorPose2(i - 1, i, odometry, odoNoise))\n",
    "\n",
    "    # predict pose and add as initial estimate\n",
    "    predictedPose = lastPose.compose(odometry)\n",
    "    lastPose = predictedPose\n",
    "    initial.insert(i, predictedPose)\n",
    "    pose_times.append(t)\n",
    "\n",
    "print(f\"Added {M} odometry factors and initial pose estimates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de5ecf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding Range Factors...\n",
      "Added 1816 range factors.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAdding Range Factors...\")\n",
    "# Convert pose_times to numpy array for efficient search\n",
    "pose_times_np = np.array(pose_times)\n",
    "\n",
    "# Add range factors\n",
    "range_factors_added = 0\n",
    "for t_range, landmark_id, measured_range in triples:\n",
    "    # Find the pose index active at the time of the range measurement\n",
    "    # Get the index of the *last* pose time that is <= t_range\n",
    "    pose_index = np.searchsorted(pose_times_np, t_range, side='right') - 1\n",
    "    \n",
    "    # Ensure pose_index is valid (it might be -1 if t_range is before the first odometry time)\n",
    "    if pose_index < 0:\n",
    "        # print(f\"Warning: Range measurement at time {t_range} is before the first pose time {pose_times_np[0]}. Skipping.\")\n",
    "        pose_index = 0 # Or skip the measurement\n",
    "\n",
    "    landmark_key = symbol('L', landmark_id)\n",
    "    graph.add(gtsam.RangeFactor2D(pose_index, landmark_key, measured_range, rangeNoise))\n",
    "    range_factors_added += 1\n",
    "\n",
    "print(f\"Added {range_factors_added} range factors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4af6f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing the factor graph...\n",
      "Optimization complete in 8.03 seconds.\n",
      "Initial Error: 298.291739023152\n",
      "Final Error: 0.8770075415268919\n",
      "Initial error: 298.292, values: 4095\n",
      "iter      cost      cost_change    lambda  success iter_time\n",
      "   0       139725     -1.4e+05      1e-05      1       0.16\n",
      "iter      cost      cost_change    lambda  success iter_time\n",
      "   0      8.9e+03     -8.6e+03     0.0001      1        0.2\n",
      "iter      cost      cost_change    lambda  success iter_time\n",
      "   0      1.9e+02      1.1e+02      0.001      1       0.12\n",
      "   1      2.7e+03     -2.5e+03     0.0001      1       0.23\n",
      "   1      1.1e+02           82      0.001      1       0.18\n",
      "   2      1.7e+03     -1.6e+03     0.0001      1       0.26\n",
      "   2           84           22      0.001      1       0.26\n",
      "   3      5.9e+02     -5.1e+02     0.0001      1       0.08\n",
      "   3           75          8.7      0.001      1       0.09\n",
      "   4      2.8e+02       -2e+02     0.0001      1       0.08\n",
      "   4           66            9      0.001      1       0.09\n",
      "   5      1.9e+02     -1.3e+02     0.0001      1       0.09\n",
      "   5           53           13      0.001      1       0.09\n",
      "   6      2.6e+02     -2.1e+02     0.0001      1       0.07\n",
      "   6           38           15      0.001      1       0.09\n",
      "   7      1.3e+02          -88     0.0001      1       0.11\n",
      "   7           24           13      0.001      1       0.13\n",
      "   8           90          -65     0.0001      1       0.13\n",
      "   8           20            4      0.001      1        0.1\n",
      "   9           61          -40     0.0001      1       0.08\n",
      "   9           18            2      0.001      1       0.12\n",
      "  10           44          -26     0.0001      1       0.15\n",
      "  10           17          1.8      0.001      1       0.12\n",
      "  11           34          -17     0.0001      1       0.11\n",
      "  11           15          1.5      0.001      1       0.05\n",
      "  12           26          -11     0.0001      1       0.11\n",
      "  12           14          1.3      0.001      1       0.09\n",
      "  13           21         -7.6     0.0001      1       0.09\n",
      "  13           13          1.2      0.001      1       0.12\n",
      "  14           18           -5     0.0001      1       0.12\n",
      "  14           12            1      0.001      1       0.13\n",
      "  15           15         -3.2     0.0001      1        0.1\n",
      "  15           11         0.89      0.001      1       0.08\n",
      "  16           13         -1.9     0.0001      1       0.13\n",
      "  16           10         0.78      0.001      1       0.08\n",
      "  17           11           -1     0.0001      1        0.1\n",
      "  17          9.3         0.69      0.001      1       0.14\n",
      "  18          9.7        -0.39     0.0001      1       0.07\n",
      "  18          8.7         0.61      0.001      1       0.08\n",
      "  19          8.6        0.058     0.0001      1        0.1\n",
      "  20           66          -58      1e-05      1        0.1\n",
      "  20            5          3.6     0.0001      1        0.1\n",
      "  21           22          -17      1e-05      1       0.09\n",
      "  21          3.5          1.4     0.0001      1       0.09\n",
      "  22          9.3         -5.8      1e-05      1        0.1\n",
      "  22            3         0.57     0.0001      1       0.18\n",
      "  23            5           -2      1e-05      1       0.06\n",
      "  23          2.6         0.34     0.0001      1       0.06\n",
      "  24          3.3         -0.7      1e-05      1       0.09\n",
      "  24          2.4         0.25     0.0001      1        0.1\n",
      "  25          2.5        -0.19      1e-05      1       0.09\n",
      "  25          2.2         0.21     0.0001      1       0.06\n",
      "  26          2.1        0.036      1e-05      1       0.13\n",
      "  27          3.6         -1.5      1e-06      1       0.13\n",
      "  27          1.1         0.99      1e-05      1       0.12\n",
      "  28          1.4        -0.24      1e-06      1        0.1\n",
      "  28         0.93          0.2      1e-05      1       0.16\n",
      "  29         0.96        -0.03      1e-06      1       0.12\n",
      "  29         0.88        0.048      1e-05      1       0.11\n",
      "  30         0.88      0.00065      1e-06      1       0.18\n"
     ]
    }
   ],
   "source": [
    "# Graph built, optimize!\n",
    "print(\"\\nOptimizing the factor graph...\")\n",
    "start_time = time.time()\n",
    "\n",
    "params = gtsam.LevenbergMarquardtParams()\n",
    "params.setRelativeErrorTol(1e-3) # Convergence tolerance\n",
    "params.setVerbosityLM(\"SUMMARY\") # Print LM progress\n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, initial, params)\n",
    "result = optimizer.optimize()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Optimization complete in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "print(f\"Initial Error: {graph.error(initial)}\")\n",
    "print(f\"Final Error: {graph.error(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77201bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Landmark Locations:\n",
      "  L0: [-48.11371377  31.9206595 ]\n",
      "  L1: [-80.93080228  53.94011755]\n",
      "  L5: [-47.58464216 -19.97679349]\n",
      "  L6: [-17.70794095  66.35831441]\n"
     ]
    }
   ],
   "source": [
    "# Print optimized landmarks:\n",
    "print(\"\\nOptimized Landmark Locations:\")\n",
    "for j in [0, 1, 5, 6]: # Print specific landmarks like MATLAB example\n",
    "    if j in sorted_landmark_ids:\n",
    "        landmark_key = gtsam.symbol('L', j)\n",
    "        try:\n",
    "            p = result.atPoint2(landmark_key)\n",
    "            print(f\"  L{j}: {p}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  L{j}: Not found in result ({e})\")\n",
    "    else:\n",
    "        print(f\"  L{j}: Not present in TD data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b679400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted 4091 final poses and 4 landmarks.\n"
     ]
    }
   ],
   "source": [
    "# Extract poses and landmarks for plotting\n",
    "poses_result = gtsam.utilities.allPose2s(result)\n",
    "landmarks_result = gtsam.utilities.extractPoint2(result)\n",
    "positions_result = np.array([poses_result.atPose2(key).translation() \n",
    "                             for key in range(M + 1)]) # Poses 0 to M\n",
    "\n",
    "# Also extract initial estimate poses (dead reckoning)\n",
    "poses_initial = gtsam.utilities.allPose2s(initial)\n",
    "positions_initial = np.array([poses_initial.atPose2(key).translation() \n",
    "                              for key in range(M + 1)])\n",
    "\n",
    "print(f\"\\nExtracted {positions_result.shape[0]} final poses and {landmarks_result.shape[0]} landmarks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ebb3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using Plotly (similar to iSAM example)\n",
    "fig = px.line(x=positions_initial[:,0], y=positions_initial[:,1], title='Plaza2 Batch SLAM Result')\n",
    "fig.data[0].name = 'Initial (Odometry)'\n",
    "fig.data[0].showlegend = True\n",
    "fig.data[0].line.color = 'orange'\n",
    "fig.data[0].line.dash = 'dash'\n",
    "\n",
    "fig.add_scatter(x=positions_result[:,0], y=positions_result[:,1], mode='lines', \n",
    "                line=dict(color='black'), name='Optimized Path')\n",
    "\n",
    "fig.add_scatter(x=landmarks_result[:,0], y=landmarks_result[:,1], mode='markers', \n",
    "                marker=dict(color='red', symbol='star', size=8), name='Landmarks')\n",
    "\n",
    "# Configure layout\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=40, b=20), \n",
    "                  legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
    "                  xaxis_title=\"X (m)\", yaxis_title=\"Y (m)\")\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1) # Ensure aspect ratio is 1:1\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\"\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f412bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized poses written to data/range/unoptimized.txt (shifted and scaled by 1/10)\n"
     ]
    }
   ],
   "source": [
    "# Write the initial (odometry) robot poses to data/range/unoptimized.txt for simulation replay (shifted so first x,y is 0,0)\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "x0, y0 = positions_initial[0]\n",
    "with open('data/range/unoptimized.txt', 'w') as f:\n",
    "    for i in range(positions_initial.shape[0]):\n",
    "        x, y = positions_initial[i]\n",
    "        x = (x - x0) / 10\n",
    "        y = (y - y0) / 10\n",
    "        # Try to get heading if available (from poses_initial)\n",
    "        try:\n",
    "            theta = poses_initial.atPose2(i).theta()\n",
    "        except Exception:\n",
    "            theta = 0.0\n",
    "        f.write(f\"{x} {y} {theta}\\n\")\n",
    "print(\"Unoptimized poses written to data/range/unoptimized.txt (shifted and scaled by 1/10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f57235b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized poses written to data/range/optimized.txt (shifted and scaled by 1/10)\n"
     ]
    }
   ],
   "source": [
    "# Write the optimized robot poses to data/range/optimized.txt for simulation replay (shifted so first x,y is 0,0)\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "x0_opt, y0_opt = positions_result[0]\n",
    "with open('data/range/optimized.txt', 'w') as f:\n",
    "    for i in range(positions_result.shape[0]):\n",
    "        x, y = positions_result[i]\n",
    "        x = (x - x0_opt) / 10\n",
    "        y = (y - y0_opt) / 10\n",
    "        # Try to get heading if available (from poses_result)\n",
    "        try:\n",
    "            theta = poses_result.atPose2(i).theta()\n",
    "        except Exception:\n",
    "            theta = 0.0\n",
    "        f.write(f\"{x} {y} {theta}\\n\")\n",
    "print(\"Optimized poses written to data/range/optimized.txt (shifted and scaled by 1/10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5294868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized landmark positions written to data/range/landmarks_optimized.txt\n"
     ]
    }
   ],
   "source": [
    "# Write optimized landmark positions to file\n",
    "os.makedirs('data', exist_ok=True)\n",
    "with open('data/range/landmarks_optimized.txt', 'w') as f:\n",
    "    for lx, ly in landmarks_result:\n",
    "        rlx = (lx - x0_opt) / 10\n",
    "        rly = (ly - y0_opt) / 10\n",
    "        f.write(f\"{rlx} {rly}\\n\")\n",
    "print(\"Optimized landmark positions written to data/range/landmarks_optimized.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6cd8616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized landmark positions written to data/range/landmarks_unoptimized.txt\n"
     ]
    }
   ],
   "source": [
    "landmarks_initial = gtsam.utilities.extractPoint2(initial)\n",
    "# Write unoptimized landmark positions to file\n",
    "os.makedirs('data', exist_ok=True)\n",
    "with open('data/range/landmarks_unoptimized.txt', 'w') as f:\n",
    "    for lx, ly in landmarks_initial:\n",
    "        rlx = (lx - x0_opt) / 10\n",
    "        rly = (ly - y0_opt) / 10\n",
    "        f.write(f\"{rlx} {rly}\\n\")\n",
    "print(\"Unoptimized landmark positions written to data/range/landmarks_unoptimized.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eca79a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
